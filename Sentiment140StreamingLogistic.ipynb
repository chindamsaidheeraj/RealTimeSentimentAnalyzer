{"cells":[{"cell_type":"markdown","source":["## Setting the configuration for Azure Storage Account access"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1445894c-0c5f-4a8d-ada6-2065b7f4a7be"}}},{"cell_type":"code","source":["spark.conf.set(\n  \"fs.azure.account.key.twittergenstorage.blob.core.windows.net\",\n  \"okEjVsoQ+OmK+TNB4/gpnkiDAVNofpG1IxYTOFx+j1JJGQHw9JIk2zakiqyoXm4fmtrAH66vXQB0+AStEZgvtg==\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb5b5dd4-37f6-44c4-88d8-3a3d7a6b8c29"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Copying the model to Azure Storage Account"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1aa96517-df66-4f4c-b228-12d4a0c76809"}}},{"cell_type":"code","source":["dbutils.fs.cp(\"wasbs://realtimetwitterdata@twittergenstorage.blob.core.windows.net/models/logistic-regression-hash\",\"FileStore/models/logistic-regression-hash\",recurse=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7d82e68-24a5-418b-acc0-f43083b11436"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[2]: True","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[2]: True"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Importing the libraries and creating the transformers, estimator and the pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"190c624f-b884-4bb5-925f-f1e979cd3a25"}}},{"cell_type":"code","source":["from pyspark.ml import PipelineModel\n\n!pip install spark-nlp==4.0.1\nimport sparknlp\nfrom sparknlp.base import *\nfrom sparknlp.annotator import *\n\nimport pyspark.ml.feature as feats\nfrom pyspark.ml.feature import StringIndexer, IDF, HashingTF\nfrom pyspark.ml.classification import LogisticRegression\n\ndocumentAssembler = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\ntokenizer = Tokenizer().setInputCols(\"document\").setOutputCol(\"token\")\n\nnormalizer = Normalizer() \\\n    .setInputCols([\"token\"]) \\\n    .setOutputCol(\"normalized\")\\\n    .setLowercase(True)\\\n    .setCleanupPatterns([\"[^\\w\\d\\s]\"]) # remove punctuations (keep alphanumeric chars)\n    # if we don't set CleanupPatterns, it will only keep alphabet letters ([^A-Za-z])\n\nstopwords_cleaner = StopWordsCleaner()\\\n      .setInputCols(\"normalized\")\\\n      .setOutputCol(\"cleanTokens\")\\\n      .setCaseSensitive(False)\\\n\nfinisher = Finisher().setInputCols(\"cleanTokens\").setOutputCols(\"output\").setOutputAsArray(False).setAnnotationSplitSymbol(' ')\n\ntokenizer2 = feats.Tokenizer().setInputCol(\"output\").setOutputCol(\"token_tweet\")\n\nhashtf = HashingTF(numFeatures=2**16, inputCol=\"token_tweet\", outputCol='tf')\nidf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\nlabel_stringIdx = StringIndexer(inputCol = \"target\", outputCol = \"label\")\n\nlr = LogisticRegression(maxIter = 100, labelCol=\"label\", featuresCol=\"features\", predictionCol=\"prediction\")\n\npipeline = PipelineModel(stages=[documentAssembler,tokenizer,normalizer,stopwords_cleaner,finisher,tokenizer2,hashtf,idf,label_stringIdx,lr])\npipelineFit = pipeline.load(\"dbfs:/FileStore/models/logistic-regression-hash\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbf6b6d4-bd85-418b-b65b-33d3e8601fed"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Requirement already satisfied: spark-nlp==4.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-18b8da7c-6425-486f-9925-06c45f4f6e0c/lib/python3.9/site-packages (4.0.1)\r\n\u001B[33mWARNING: You are using pip version 21.2.4; however, version 22.2.2 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-18b8da7c-6425-486f-9925-06c45f4f6e0c/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: spark-nlp==4.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-18b8da7c-6425-486f-9925-06c45f4f6e0c/lib/python3.9/site-packages (4.0.1)\r\n\u001B[33mWARNING: You are using pip version 21.2.4; however, version 22.2.2 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-18b8da7c-6425-486f-9925-06c45f4f6e0c/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Creating configuration for Azure Event Hub"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e4ae7579-7aaa-4992-a04f-0e2b03836068"}}},{"cell_type":"code","source":["# Initialize event hub config dictionary with connectionString\n\nehConf = {}\n\nconnectionString = \"Endpoint=sb://streamer.servicebus.windows.net/;SharedAccessKeyName=manager;SharedAccessKey=zXFkFXKED4g14LDP3pw/XibU4a0RO/TTJ0VB34inmuI=;EntityPath=tweets\"\n\nehConf['eventhubs.connectionString'] = connectionString\n\n# Add consumer group to the ehConf dictionary\n\nehConf['eventhubs.consumerGroup'] = \"$Default\"\n\n# Encrypt ehConf connectionString property\n\nehConf['eventhubs.connectionString'] = sc._jvm.org.apache.spark.eventhubs.EventHubsUtils.encrypt(connectionString)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c3c77ca9-342f-45dc-82d4-44f1184a010e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.readStream.format(\"eventhubs\").options(**ehConf).load()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24995118-4d7d-42c7-8619-400c85aadf52"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Decoding the input stream"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e6a551c4-0ca9-4b16-a8a7-18f761cf556d"}}},{"cell_type":"code","source":["from pyspark.sql.types import *\n\nimport  pyspark.sql.functions as F\n\nevents_schema = StructType([\n   StructField(\"target\",IntegerType(),True),\n   StructField(\"text\",StringType(),True)\n   ]\n )\n\ndecoded_df = df.selectExpr(\"cast (body as string) as json\").select(F.from_json(\"json\",events_schema).alias(\"data\")).select(\"data.*\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff241709-ab9c-4ef5-97c4-fd3e8c9cf7be"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["result = pipelineFit.transform(decoded_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82f24fd2-b4b9-49ad-80df-c505a168cd97"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Creating the Databricks Delta table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e99525c-5eb6-4f06-8734-43067140026c"}}},{"cell_type":"code","source":["%sql\nCREATE TABLE IF NOT EXISTS default.modelOutput (\n  timestamp TIMESTAMP,\n  target TINYINT,\n  prediction TINYINT,\n  clean_text STRING\n) USING DELTA"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd615fcc-c269-4417-9180-ca94fe68c945"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Starting the Stream consumer and writing to the Delta table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e64d66d8-d655-4eb5-8628-60c0c5a2b464"}}},{"cell_type":"code","source":["from pyspark.sql.functions import col\nfrom pyspark.sql.functions import current_timestamp"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ce19826-4cdc-4680-a811-add85edf7824"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["result.withColumn(\"clean_text\", result[\"output\"]) \\\n    .select(col('target'), col('prediction'), col('clean_text')) \\\n    .withColumn(\"timestamp\", current_timestamp()) \\\n    .withColumn(\"prediction\", result[\"prediction\"].cast(ByteType())) \\\n    .withColumn(\"target\", result[\"target\"].cast(ByteType())) \\\n    .writeStream \\\n    .format(\"delta\") \\\n    .outputMode(\"append\") \\\n    .option(\"checkpointLocation\", \"/tmp/delta/_checkpoints/\") \\\n    .start(\"/user/hive/warehouse/modeloutput\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc5b042e-5eec-4a69-a6b9-ca0a5f1d9378"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[11]: <pyspark.sql.streaming.query.StreamingQuery at 0x7fcb75207400>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[11]: <pyspark.sql.streaming.query.StreamingQuery at 0x7fcb75207400>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Fetching sample records from the Databricks Delta table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"466ea1bd-d10d-4bd0-bc6e-4009ee4f8690"}}},{"cell_type":"code","source":["%sql\nselect * from default.modelOutput order by timestamp desc limit 10;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c458231b-2421-497f-86ae-5354b8a4d797"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["2022-08-17T08:23:31.607+0000",0,0,"monday morning still four days week"],["2022-08-17T08:23:31.607+0000",0,0,"concerts hurt back lol"],["2022-08-17T08:23:31.607+0000",0,0,"cant sleep miss ipod amongst things another devoured comic need heaps stupid dishevled comic sectionborders"],["2022-08-17T08:23:31.607+0000",0,0,"waiting brownies get doneheading chadleys later fun wish see baby today"],["2022-08-17T08:23:31.607+0000",0,0,"rawr dont want go school tomorrow listening song makes sad"],["2022-08-17T08:23:31.607+0000",1,0,"bios compromise made security mail servers user accounts vulnerable bad passwords jc"],["2022-08-17T08:23:31.607+0000",1,1,"haha first sitemodel icon httpi686photobucketcomalbumsvv223lautnerx3sitemodelx3png"],["2022-08-17T08:23:31.607+0000",1,1,"nice work today wife order driving father make radiohosting long eyes open lol take look"],["2022-08-17T08:23:31.607+0000",1,1,"admiring beautiful farm ft going onto rc"],["2022-08-17T08:23:31.607+0000",1,1,"reneetakeover phoebe friends course"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"timestamp","type":"\"timestamp\"","metadata":"{}"},{"name":"target","type":"\"byte\"","metadata":"{}"},{"name":"prediction","type":"\"byte\"","metadata":"{}"},{"name":"clean_text","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>timestamp</th><th>target</th><th>prediction</th><th>clean_text</th></tr></thead><tbody><tr><td>2022-08-17T08:23:31.607+0000</td><td>0</td><td>0</td><td>monday morning still four days week</td></tr><tr><td>2022-08-17T08:23:31.607+0000</td><td>0</td><td>0</td><td>concerts hurt back lol</td></tr><tr><td>2022-08-17T08:23:31.607+0000</td><td>0</td><td>0</td><td>cant sleep miss ipod amongst things another devoured comic need heaps stupid dishevled comic sectionborders</td></tr><tr><td>2022-08-17T08:23:31.607+0000</td><td>0</td><td>0</td><td>waiting brownies get doneheading chadleys later fun wish see baby today</td></tr><tr><td>2022-08-17T08:23:31.607+0000</td><td>0</td><td>0</td><td>rawr dont want go school tomorrow listening song makes sad</td></tr><tr><td>2022-08-17T08:23:31.607+0000</td><td>1</td><td>0</td><td>bios compromise made security mail servers user accounts vulnerable bad passwords jc</td></tr><tr><td>2022-08-17T08:23:31.607+0000</td><td>1</td><td>1</td><td>haha first sitemodel icon httpi686photobucketcomalbumsvv223lautnerx3sitemodelx3png</td></tr><tr><td>2022-08-17T08:23:31.607+0000</td><td>1</td><td>1</td><td>nice work today wife order driving father make radiohosting long eyes open lol take look</td></tr><tr><td>2022-08-17T08:23:31.607+0000</td><td>1</td><td>1</td><td>admiring beautiful farm ft going onto rc</td></tr><tr><td>2022-08-17T08:23:31.607+0000</td><td>1</td><td>1</td><td>reneetakeover phoebe friends course</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9510dd12-3b8e-47d0-afa9-e667de68ea9f"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Sentiment140StreamingLogistic","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":2299614086110987,"dataframes":["_sqldf"]}},"language":"python","widgets":{},"notebookOrigID":2299614086110965}},"nbformat":4,"nbformat_minor":0}
